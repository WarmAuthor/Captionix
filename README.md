# Captionix â€” AI-Powered Smart Image Analyzer & Caption Generator

Captionix is an intelligent image understanding system that integrates **Data Science**, **Machine Learning**, **Computer Vision**, and **Generative AI** into a single Streamlit web application.

Upload any image and get instant results across four AI pipelines:

---

## ğŸš€ Features

| Module | Model | Dataset | Output |
|--------|-------|---------|--------|
| ğŸ¤– **Image Captioning** | BLIP (`Salesforce/blip-image-captioning-base`) | COCO | Natural language description |
| ğŸ‘ï¸ **Object Detection** | YOLOv8n (`yolov8n-oiv7.pt`) | Open Images V7 (601 classes) | Annotated bounding boxes |
| ğŸ§  **Classification â€” ResNet-50** | Pretrained ResNet-50 (torchvision) | ImageNet-1K (1 000 classes) | Top-5 predictions with confidence |
| ğŸš€ **Classification â€” YOLOv8-cls** | YOLOv8n-cls (`yolov8n-cls.pt`) | ImageNet-1K (1 000 classes) | Top-5 predictions with confidence |
| ğŸ“Š **Image EDA** | NumPy / Matplotlib | Uploaded image | Dimensions, channel stats, RGB histogram |

---

## ğŸ–¥ï¸ App Structure

```
Wipro_1/
â”œâ”€â”€ app.py                    # Streamlit UI (main entry point)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ classifier.py         # ResNet-50 + YOLOv8-cls ImageNet inference & fine-tuning
â”‚   â”œâ”€â”€ image_caption.py      # BLIP captioning
â”‚   â”œâ”€â”€ object_detection.py   # YOLO detection helper
â”‚   â””â”€â”€ data_analysis.py      # Standalone EDA script (class-folder datasets)
â”œâ”€â”€ models/                   # Saved fine-tuned weights (if any)
â”œâ”€â”€ data/                     # Local images / custom dataset
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

```bash
# 1. Clone the repo
git clone https://github.com/<your-username>/Wipro_1.git
cd Wipro_1

# 2. Create & activate a virtual environment (recommended)
python -m venv .venv
source .venv/bin/activate      # macOS / Linux
# .venv\Scripts\activate       # Windows

# 3. Install dependencies
pip install -r requirements.txt
```

> **PyTorch GPU (optional):** Replace the `torch` / `torchvision` lines in `requirements.txt` with the CUDA-specific wheel from [pytorch.org](https://pytorch.org/get-started/locally/).

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

Open **http://localhost:8501** in your browser.  
All models (BLIP, YOLOv8, ResNet-50, YOLOv8-cls) download automatically on first run.

---

## ğŸ§  Classification Details

Both classifiers are **pretrained on ImageNet-1K** â€” no training data download required.

| | ResNet-50 | YOLOv8n-cls |
|---|---|---|
| **Weights** | `torchvision` built-in | Auto-downloaded by `ultralytics` (~6 MB) |
| **Inference** | TTA (5-view averaging) | Single forward pass |
| **Labels** | Loaded from `torchvision` metadata | Loaded from model `names` dict |
| **Top-1 accuracy** | ~76 % on ImageNet val | ~69 % on ImageNet val |

Results are displayed as a **merged top-5 comparison table** in the app.

### Optional Fine-Tuning
Fine-tune on your own ImageNet-format dataset (subfolder per class):

```bash
python scripts/classifier.py --train \
  --data path/to/dataset \   # must contain train/ and val/ subdirs
  --epochs 10 \
  --arch resnet50 \
  --save models/my_model.pth
```

---

## ğŸ‘ï¸ Object Detection Details

The app uses **YOLOv8n trained on Open Images V7** (`yolov8n-oiv7.pt`) with **601 object classes** â€” far broader than COCO's 80 classes.  
The model downloads automatically via `ultralytics` on first use.

---

## ğŸ“Š Data Science / EDA

The **Image EDA** section (bottom of the app) automatically computes for every uploaded image:
- Width, Height, Channels
- Per-channel mean and standard deviation (R, G, B)
- RGB pixel intensity histogram

---

## âœ… Advantages

- **No training required** â€” Uses pretrained models (ResNet-50, YOLOv8) out of the box with state-of-the-art accuracy
- **Multi-model comparison** â€” Simultaneously runs ResNet-50 and YOLOv8-cls and displays results side-by-side for the same image
- **601-class detection** â€” YOLOv8 Open Images V7 detects far more object types than standard COCO models (cars, animals, instruments, household items, etc.)
- **Generative AI captioning** â€” BLIP produces natural language descriptions, not just labels
- **Live EDA** â€” Instant per-image statistics and RGB histogram without any external script
- **Lightweight deployment** â€” All models auto-download on first use; no manual setup of large datasets
- **Scalable architecture** â€” Modular `scripts/` structure makes it easy to swap models or add new pipelines
- **Cloud-ready** â€” Includes `packages.txt` and `.streamlit/config.toml` for one-click Streamlit Community Cloud deployment

---

## ğŸ› ï¸ Technologies

- **Python 3.9+**
- **PyTorch** + **torchvision** â€” ResNet-50 classification
- **Ultralytics YOLOv8** â€” Object detection (OIV7) & image classification (ImageNet)
- **Hugging Face Transformers** â€” BLIP image captioning
- **Streamlit** â€” Web UI
- **NumPy / Pandas / Matplotlib** â€” EDA & data handling